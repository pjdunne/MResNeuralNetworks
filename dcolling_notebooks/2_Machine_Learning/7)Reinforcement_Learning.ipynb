{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning \n",
    "\n",
    "Reinforcement Learning is the cutting-edge approach in artificial intelligence that empowers machines to learn by interacting with their environment. Just like a skillful player mastering a game, this innovative technique enables AI to make smart decisions and improve performance through trial and error. By rewarding positive outcomes and penalising mistakes, Reinforcement Learning paves the way for autonomous agents that learn to navigate complex challenges and conquer the unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real life example:\n",
    "AlphaGo, the revolutionary AI developed by DeepMind, employs Reinforcement Learning as a crucial component of its strategy. Through a combination of supervised learning from human expert games and reinforcement learning by playing against itself, AlphaGo hones its skills and adapts its gameplay. This reinforcement learning process allows AlphaGo to refine its moves, prioritise winning strategies, and continuously evolve, eventually achieving superhuman proficiency in the intricate game of Go. The result is a monumental breakthrough in the world of AI and a testament to the power of Reinforcement Learning in conquering complex challenges. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will go through a simple example of reinforcement learning.\n",
    "\n",
    "A game of rock paper scissors is designed, you may try to write your own example to implement a simple game.\n",
    "\n",
    "What we want is to let you the player choose an option and the computer to also do the same thing, then we decide if you or the player has won the game:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise: Write your version of this implementation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of code below is a version of implementation:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: scissors\n",
      "user wins\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#### This is how a basic one to one game of rock paper and scissors work\n",
    "def users_choice():\n",
    "    print(\"Let's play rock, paper, scissors\")\n",
    "    while True:\n",
    "        choice = input(\"Enter your choice (rock, paper, or scissors): \")\n",
    "        if choice in [\"rock\", \"paper\", \"scissors\"]:\n",
    "            return choice\n",
    "        else:\n",
    "            print(\"Invalid choice. Try again.\")\n",
    "\n",
    "\n",
    "def comp_trial():\n",
    "    options = [\"rock\", \"paper\", \"scissors\"]\n",
    "    choice = random.choice(options)\n",
    "    return choice\n",
    "\n",
    "\n",
    "def rule(user_choice, comp_choice):\n",
    "    '''\n",
    "    This shows all the outcomes of the game,\n",
    "    the if statements can be shortened to three\n",
    "    '''\n",
    "    if user_choice == comp_choice:\n",
    "        return \"draw\"\n",
    "    elif user_choice == \"rock\" and comp_choice == \"scissors\":\n",
    "        return \"user wins\"\n",
    "    elif user_choice == \"scissors\" and comp_choice == \"rock\":\n",
    "        return \"computer wins\"\n",
    "    elif user_choice == \"paper\" and comp_choice == \"rock\":\n",
    "        return \"user wins\"\n",
    "    elif user_choice == \"rock\" and comp_choice == \"paper\":\n",
    "        return \"computer wins\"\n",
    "    elif user_choice == \"scissors\" and comp_choice == \"paper\":\n",
    "        return \"user wins\"\n",
    "    elif user_choice == \"paper\" and comp_choice == \"scissors\":\n",
    "        return \"computer wins\"\n",
    "\n",
    "\n",
    "comp_choice = comp_trial()\n",
    "user_choice = users_choice()\n",
    "\n",
    "\n",
    "print(\"Your choice:\", user_choice)\n",
    "print(\"I will choose:\", comp_choice)\n",
    "\n",
    "result = rule(user_choice, comp_choice)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< Updated upstream
    "## Adding a reward system\n",
=======
    "## Adding a Reward System\n",
>>>>>>> Stashed changes
    "\n",
    "The idea of reinforcement learning is about letting the machine know what outcomes is the outcome that we want to see. To do this we can set up a reward system:\n",
    "\n",
    "Here I want the player to win the game and I will let the code know this by adding in a reward system. In this section we are implementing a reward system and the machine will append these values to be assessed."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 2,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def users_choice():\n",
<<<<<<< Updated upstream
    "\n",
=======
>>>>>>> Stashed changes
    "    print(\"Let's play rock, paper, scissors\")\n",
    "    while True:\n",
    "        choice = input(\"Enter your choice (rock, paper, or scissors): \")\n",
    "        if choice in [\"rock\", \"paper\", \"scissors\"]:\n",
    "            return choice\n",
    "        else:\n",
    "            print(\"Invalid choice. Try again.\")\n",
    "\n",
    "\n",
    "def comp_trial():\n",
    "    options = [\"rock\", \"paper\", \"scissors\"]\n",
    "    choice = random.choice(options)\n",
    "    return choice\n",
    "\n",
    "\n",
    "def get_reward(user_choice, comp_choice):\n",
<<<<<<< Updated upstream
=======
    "    ''' \n",
    "    Simplify the rules\n",
    "    '''\n",
>>>>>>> Stashed changes
    "    if user_choice == comp_choice:\n",
    "        return 0  # Draw\n",
    "    elif (\n",
    "        (user_choice == \"rock\" and comp_choice == \"scissors\")\n",
    "        or (user_choice == \"scissors\" and comp_choice == \"paper\")\n",
    "        or (user_choice == \"paper\" and comp_choice == \"rock\")\n",
    "    ):\n",
    "        return 1  # Win\n",
    "    else:\n",
    "        return -1  # Lose\n",
    "\n",
    "\n",
    "def play_game():\n",
    "    user_choice = users_choice()\n",
    "    comp_choice = comp_trial()\n",
    "\n",
    "    print(\"Your choice:\", user_choice)\n",
    "    print(\"I will choose:\", comp_choice)\n",
    "\n",
    "    reward = get_reward(user_choice, comp_choice)\n",
    "    return reward\n",
    "\n",
    "\n",
<<<<<<< Updated upstream
    "num_episodes = 15\n",
=======
    "num_episodes = 3\n",
>>>>>>> Stashed changes
    "total_reward = 0\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    reward = play_game()\n",
    "    total_reward += reward\n",
    "\n",
    "# visualise reward, so far we are not using the reward yet\n",
    "average_reward = total_reward / num_episodes\n",
    "print(\"Average Reward over {} episodes: {}\".format(num_episodes, average_reward))"
   ]
<<<<<<< Updated upstream
=======
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning  \n",
    "\n",
    "We further this concept by starting to use the reward system to tell the computer to let the player win the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's play rock, paper, or scissors\n",
      "scissors\n",
      "['scissors']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "options = [\"rock\", \"paper\", \"scissors\"]\n",
    "num_episodes = 20\n",
    "\n",
    "\n",
    "list_users_choice = []\n",
    "\n",
    "def user_choice():\n",
    "    print(\"Let's play rock, paper, or scissors\")\n",
    "    for episode in range(num_episodes):\n",
    "        choice = random.choice(options)\n",
    "        list_users_choice.append(choice)\n",
    "        return choice\n",
    "\n",
    "print(user_choice())\n",
    "print(list_users_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: paper\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: scissors\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: paper\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: scissors\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: scissors\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: scissors\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: scissors\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: rock\n",
      "Let's play rock, paper, scissors\n",
      "Your choice: rock\n",
      "I will choose: paper\n",
      "Average Reward over 20 episodes: 0.1\n"
     ]
    }
   ],
   "source": [
    "# The code is now documented, extension used mintlify extension in VS Code\n",
    "# Formatter Black(VS Code extension)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def users_choice():\n",
    "    \"\"\"\n",
    "    The function `users_choice` prompts the user to enter their choice of \"rock\", \"paper\", or \"scissors\"\n",
    "    and returns the valid choice.\n",
    "    :return: the user's choice of \"rock\", \"paper\", or \"scissors\".\n",
    "    \"\"\"\n",
    "    print(\"Let's play rock, paper, scissors\")\n",
    "    while True:\n",
    "        choice = input(\"Enter your choice (rock, paper, or scissors): \")\n",
    "        if choice in [\"rock\", \"paper\", \"scissors\"]:\n",
    "            return choice\n",
    "        else:\n",
    "            print(\"Invalid choice. Try again.\")\n",
    "\n",
    "\n",
    "options = [\"rock\", \"paper\", \"scissors\"]\n",
    "\n",
    "\n",
    "def comp_trial():\n",
    "    choice = random.choice(options)\n",
    "    return choice\n",
    "\n",
    "\n",
    "def get_reward(user_choice, comp_choice):\n",
    "    \"\"\"\n",
    "    The function \"get_reward\" determines the outcome of a rock-paper-scissors game between a user and a\n",
    "    computer, and returns a reward value based on the result.\n",
    "\n",
    "    :param user_choice: The choice made by the user. It can be \"rock\", \"paper\", or \"scissors\"\n",
    "    :param comp_choice: The choice made by the computer. It can be \"rock\", \"paper\", or \"scissors\"\n",
    "    :return: The function `get_reward` returns an integer value. It returns 0 if the user_choice and\n",
    "    comp_choice are the same, indicating a draw. It returns 1 if the user_choice beats the comp_choice,\n",
    "    indicating that the computer loses. It returns -1 if the comp_choice beats the user_choice,\n",
    "    indicating that the computer wins.\n",
    "    \"\"\"\n",
    "    if user_choice == comp_choice:\n",
    "        return 0  # Draw\n",
    "    elif (\n",
    "        (user_choice == \"rock\" and comp_choice == \"scissors\")\n",
    "        or (user_choice == \"scissors\" and comp_choice == \"paper\")\n",
    "        or (user_choice == \"paper\" and comp_choice == \"rock\")\n",
    "    ):\n",
    "        return 1  # Comp Lose\n",
    "    else:\n",
    "        return -1  # Comp Win\n",
    "\n",
    "\n",
    "num_episodes = 20\n",
    "\n",
    "# the learning rate, Just like in supervised learning settings\n",
    "alpha = 0.7\n",
    "# discount rate, closer to 1 captures long-term effective reward\n",
    "gamma = 0.6\n",
    "# Instead of just selecting the best learned Q-value action,\n",
    "# we'll sometimes favor exploring the action space further.\n",
    "# Lower epsilon value results in episodes with more penalties\n",
    "# (on average) which is obvious because we are exploring and\n",
    "# making random decisions.\n",
    "epsilon = 0.2\n",
    "\n",
    "q_table = {}\n",
    "options = [\"rock\", \"paper\", \"scissors\"]\n",
    "\n",
    "\n",
    "def action(state):\n",
    "    \"\"\"\n",
    "    The function selects an action based on the epsilon-greedy policy using a Q-table.\n",
    "\n",
    "    :param state: The \"state\" parameter represents the current state of the system or environment in\n",
    "    which the agent is operating. It could be any relevant information or data that describes the\n",
    "    current situation or context\n",
    "    :return: The action that will be taken based on the current state.\n",
    "    \"\"\"\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        action = random.choice(options)\n",
    "    else:\n",
    "        q_values = [q_table.get((state, action), 0) for action in options]\n",
    "        action = options[np.argmax(q_values)]\n",
    "    return action\n",
    "\n",
    "\n",
    "def update_q_table(state, action, next_state, reward):\n",
    "    \"\"\"\n",
    "    The function updates the Q-table based on the current state, action, next state, and reward using\n",
    "    the Q-learning algorithm.\n",
    "\n",
    "    :param state: The current state of the environment\n",
    "    :param action: The action parameter represents the action taken in the current state. It is used as\n",
    "    a key in the q_table dictionary to retrieve the corresponding Q-value\n",
    "    :param next_state: The next_state parameter represents the state that the agent transitions to after\n",
    "    taking the specified action in the current state\n",
    "    :param reward: The reward is the immediate reward received after taking the action in the current\n",
    "    state. It represents the feedback or evaluation of the action taken\n",
    "    \"\"\"\n",
    "    old_q_value = q_table.get((state, action), 0)\n",
    "    next_max = max(\n",
    "        [q_table.get((next_state, next_action), 0) for next_action in options]\n",
    "    )\n",
    "\n",
    "    new_q_value = (1 - alpha) * old_q_value + alpha * (reward + gamma * next_max)\n",
    "    q_table[(state, action)] = new_q_value\n",
    "\n",
    "\n",
    "def get_state(user_choice, comp_choice):\n",
    "    return (user_choice, comp_choice)\n",
    "\n",
    "\n",
    "def play_game(state):\n",
    "    \"\"\"\n",
    "    The function \"play_game\" allows the user to play a game against a computer opponent using the\n",
    "    Q-learning algorithm.\n",
    "\n",
    "    :param state: The state parameter represents the current state of the game. It could be any\n",
    "    information that describes the current situation or configuration of the game\n",
    "    :return: the reward and the next state.\n",
    "    \"\"\"\n",
    "    user_choice = users_choice()\n",
    "    comp_choice = action(state)  # using action selected by the Q-learning algorithm\n",
    "\n",
    "    print(\"Your choice:\", user_choice)\n",
    "    print(\"I will choose:\", comp_choice)\n",
    "\n",
    "    reward = get_reward(user_choice, comp_choice)  # calculate reward\n",
    "    next_state = comp_choice  # the next state is the current action of the computer\n",
    "\n",
    "    update_q_table(state, comp_choice, next_state, reward)  # update Q-table\n",
    "\n",
    "    return reward, next_state\n",
    "\n",
    "\n",
    "def game_loop(num_episodes):\n",
    "    \"\"\"\n",
    "    The function `game_loop` runs a specified number of episodes of a game, accumulating the rewards and\n",
    "    calculating the average reward.\n",
    "\n",
    "    :param num_episodes: The parameter \"num_episodes\" represents the number of episodes or games that\n",
    "    will be played in the game loop. Each episode consists of playing a game and updating the state and\n",
    "    reward\n",
    "    \"\"\"\n",
    "    state = random.choice(options)  # random initial state\n",
    "    total_reward = 0\n",
    "    for _ in range(num_episodes):\n",
    "        reward, state = play_game(state)\n",
    "        total_reward += reward\n",
    "\n",
    "    # visualise reward\n",
    "    average_reward = total_reward / num_episodes\n",
    "    print(\"Average Reward over {} episodes: {}\".format(num_episodes, average_reward))\n",
    "\n",
    "\n",
    "game_loop(num_episodes)\n"
   ]
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9df1b77b0caf646f19509570eac5ef5a3592ebd6cb99175979cb74b7b24a8bf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
