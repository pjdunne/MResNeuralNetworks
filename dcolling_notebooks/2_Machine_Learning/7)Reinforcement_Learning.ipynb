{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Reinforcement Learning \n",
                "\n",
                "Reinforcement Learning is the cutting-edge approach in artificial intelligence that empowers machines to learn by interacting with their environment. Just like a skillful player mastering a game, this innovative technique enables AI to make smart decisions and improve performance through trial and error. By rewarding positive outcomes and penalising mistakes, Reinforcement Learning paves the way for autonomous agents that learn to navigate complex challenges and conquer the unknown."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<hr style=\"border:2px solid gray\">\n",
                "\n",
                "## Index: <a id='index'></a>\n",
                "1. [Reward System](#reward-system)\n",
                "1. [Q-Learn](#QL)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Real life example:\n",
                "AlphaGo, the revolutionary AI developed by DeepMind, employs Reinforcement Learning as a crucial component of its strategy. Through a combination of supervised learning from human expert games and reinforcement learning by playing against itself, AlphaGo hones its skills and adapts its gameplay. This reinforcement learning process allows AlphaGo to refine its moves, prioritise winning strategies, and continuously evolve, eventually achieving superhuman proficiency in the intricate game of Go. The result is a monumental breakthrough in the world of AI and a testament to the power of Reinforcement Learning in conquering complex challenges. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## In this notebook...\n",
                "\n",
                "we will go through a simple example of reinforcement learning.\n",
                "\n",
                "A game of rock paper scissors is designed, you may try to write your own example to implement a simple game.\n",
                "\n",
                "What we want is to let you the player choose an option and the computer to also do the same thing, then we decide if you or the player has won the game:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"background-color: #FFF8C6\">\n",
                "\n",
                "## Exercise: Write your version of this implementation..."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The set of code below is a version of implementation:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Let's play rock, paper, scissors\n",
                        "Your choice: rock\n",
                        "I will choose: scissors\n",
                        "user wins\n"
                    ]
                }
            ],
            "source": [
                "import random\n",
                "import numpy as np\n",
                "\n",
                "\n",
                "#### This is how a basic one to one game of rock paper and scissors work\n",
                "def users_choice():\n",
                "    print(\"Let's play rock, paper, scissors\")\n",
                "    while True:\n",
                "        choice = input(\"Enter your choice (rock, paper, or scissors): \")\n",
                "        if choice in [\"rock\", \"paper\", \"scissors\"]:\n",
                "            return choice\n",
                "        else:\n",
                "            print(\"Invalid choice. Try again.\")\n",
                "\n",
                "\n",
                "def comp_trial():\n",
                "    options = [\"rock\", \"paper\", \"scissors\"]\n",
                "    choice = random.choice(options)\n",
                "    return choice\n",
                "\n",
                "\n",
                "def rule(user_choice, comp_choice):\n",
                "    '''\n",
                "    This shows all the outcomes of the game,\n",
                "    the if statements can be shortened to three\n",
                "    '''\n",
                "    if user_choice == comp_choice:\n",
                "        return \"draw\"\n",
                "    elif user_choice == \"rock\" and comp_choice == \"scissors\":\n",
                "        return \"user wins\"\n",
                "    elif user_choice == \"scissors\" and comp_choice == \"rock\":\n",
                "        return \"computer wins\"\n",
                "    elif user_choice == \"paper\" and comp_choice == \"rock\":\n",
                "        return \"user wins\"\n",
                "    elif user_choice == \"rock\" and comp_choice == \"paper\":\n",
                "        return \"computer wins\"\n",
                "    elif user_choice == \"scissors\" and comp_choice == \"paper\":\n",
                "        return \"user wins\"\n",
                "    elif user_choice == \"paper\" and comp_choice == \"scissors\":\n",
                "        return \"computer wins\"\n",
                "\n",
                "\n",
                "comp_choice = comp_trial()\n",
                "user_choice = users_choice()\n",
                "\n",
                "\n",
                "print(\"Your choice:\", user_choice)\n",
                "print(\"I will choose:\", comp_choice)\n",
                "\n",
                "result = rule(user_choice, comp_choice)\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Adding a reward system  [^](#index)\n",
                "<a id='reward-system'></a>\n",
                "\n",
                "The idea of reinforcement learning is about letting the machine know what outcomes is the outcome that we want to see. To do this we can set up a reward system:\n",
                "\n",
                "Here I want the player to win the game and I will let the code know this by adding in a reward system. In this section we are implementing a reward system and the machine will append these values to be assessed.\n",
                "\n",
                "The game is still being played randomly. How should we then use the statistics to train the model to play the way we want. In this case, play to let the player win."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n",
                "import numpy as np\n",
                "\n",
                "\n",
                "def users_choice():\n",
                "\n",
                "    print(\"Let's play rock, paper, scissors\")\n",
                "    while True:\n",
                "        choice = input(\"Enter your choice (rock, paper, or scissors): \")\n",
                "        if choice in [\"rock\", \"paper\", \"scissors\"]:\n",
                "            return choice\n",
                "        else:\n",
                "            print(\"Invalid choice. Try again.\")\n",
                "\n",
                "\n",
                "def comp_trial():\n",
                "    options = [\"rock\", \"paper\", \"scissors\"]\n",
                "    choice = random.choice(options)\n",
                "    return choice\n",
                "\n",
                "\n",
                "def get_reward(user_choice, comp_choice):\n",
                "    if user_choice == comp_choice:\n",
                "        return 0  # Draw\n",
                "    elif (\n",
                "        (user_choice == \"rock\" and comp_choice == \"scissors\")\n",
                "        or (user_choice == \"scissors\" and comp_choice == \"paper\")\n",
                "        or (user_choice == \"paper\" and comp_choice == \"rock\")\n",
                "    ):\n",
                "        return 1  # Win\n",
                "    else:\n",
                "        return -1  # Lose\n",
                "\n",
                "\n",
                "def play_game():\n",
                "    user_choice = users_choice()\n",
                "    comp_choice = comp_trial()\n",
                "\n",
                "    print(\"Your choice:\", user_choice)\n",
                "    print(\"I will choose:\", comp_choice)\n",
                "\n",
                "    reward = get_reward(user_choice, comp_choice)\n",
                "    return reward\n",
                "\n",
                "\n",
                "num_episodes = 15\n",
                "total_reward = 0\n",
                "\n",
                "for episode in range(num_episodes):\n",
                "    reward = play_game()\n",
                "    total_reward += reward\n",
                "\n",
                "# visualise reward, so far we are not using the reward yet\n",
                "average_reward = total_reward / num_episodes\n",
                "print(\"Average Reward over {} episodes: {}\".format(num_episodes, average_reward))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Reinforcement Learning in Action\n",
                "\n",
                "Let's discuss the concept of reinforcement learning further using this game.\n",
                "\n",
                "In this game, the game can be considered as the **environment**. The hand you choose to play: `input(\"Enter your choice (rock, paper, or scissors): \")` is the **state**.\n",
                "\n",
                "The computer who plays against you the player is the **agent** and the **state** represents the current situation or configuration of the **environment** that the **agent** observes. In the case of the rock-paper-scissors game, the state is not just the hand you choose to play `[\"rock, \"paper, \"scissors\"]`, but it also includes the computer's hand, as it influences the outcome of the game. So, the **state** is a combination of both your hand and the opponent's hand.\n",
                "\n",
                "After this transition, the **agent** receives a penalty or reward - with winning bringing a `+1` reward, losing bringing a `-1` penalty and drawing being a neutral action.\n",
                "\n",
                "The **policy** is then the strategy of choosing an action that gives better outcomes considering the reward system. It's a mapping from states to actions, indicating what action the agent should take in a given state. The policy can be deterministic, meaning it always chooses the same action in a specific state, or it can be stochastic, where it selects actions probabilistically. \n",
                "\n",
                "How willing the code is to selecting actions randomly/exploring different routes, would be determined by **Epsilon-Greedy exploration** - a technique used to balance exploration and exploitation during the agent's learning process. The agent uses an exploration rate (`epsilon`) to decide whether to explore a new action randomly or exploit the current best action according to the Q-values.\n",
                "\n",
                "<img src=\"https://www.learndatasci.com/documents/14/Reinforcement-Learning-Animation.gif\" alt=\"Reinforcement Learning Animation\">\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Q-Learning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Here, we implement Q-learning to enable the agent (player) to learn the best actions to take in different states. The agent uses the environment's rewards to update the Q-values over time.\n",
                "\n",
                "The Q-table is a dictionary that maps a `(state, action)` combination to the corresponding Q-value. Each Q-value represents the \"quality\" of the action taken from a specific state. Higher Q-values imply better chances of obtaining greater rewards from that action.\n",
                "\n",
                "For example, the Q-table will have entries like, with the reward system implemented:\n",
                "\n",
                "<center>\n",
                "\n",
                "|          State         |  Action  |  Q-Value  |\n",
                "|------------------------|----------|----------|\n",
                "|    Rock, Opponent=Rock  |  Rock    |   0.0    |\n",
                "|    Rock, Opponent=Rock  |  Paper   |  -1.0    |\n",
                "|    Rock, Opponent=Rock  | Scissors |   1.0    |\n",
                "|    Rock, Opponent=Paper |  Rock    |   1.0    |\n",
                "|    Rock, Opponent=Paper |  Paper   |   0.0    |\n",
                "|    Rock, Opponent=Paper | Scissors |  -1.0    |\n",
                "| Rock, Opponent=Scissors |  Rock    |  -1.0    |\n",
                "| Rock, Opponent=Scissors |  Paper   |   1.0    |\n",
                "| Rock, Opponent=Scissors | Scissors |   0.0    |\n",
                "|           ...          |   ...    |   ...    |\n",
                "\n",
                "</center>\n",
                "\n",
                "\n",
                "In this table, the rows represent different states (e.g., \"Rock, Opponent=Rock\" indicating that the agent chose Rock, and the opponent also chose Rock), the columns represent the available actions (Rock, Paper, Scissors), and the values represent the corresponding Q-values.\n",
                "\n",
                "As the agent explores and interacts with the environment, it updates the Q-values based on the rewards obtained, and future actions are influenced by these Q-values, guiding the agent towards making better decisions in the game.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q-values are updated using the following equation:\n",
                "\n",
                "$$\n",
                "Q(s, a) = Q(s, a) + α * [R(s, a) + γ * max(Q(s', a')) - Q(s, a)]\n",
                "$$\n",
                "\n",
                "- `Q(s, a)` is the Q-value of the (state, action) pair.\n",
                "α (alpha) is the learning rate, controlling the impact of new information on the Q-value updates ($0≤α≤1$).\n",
                "- `R(s, a)` is the immediate reward obtained when taking action a in state s.\n",
                "- `γ (gamma)` is the discount factor, determining the importance of future rewards ($0≤γ≤1$).\n",
                "- `max(Q(s', a'))` is the maximum Q-value among all possible actions `a'` in the next state `s'`.\n",
                "- `s'` is the next state after taking action a in state `s`.\n",
                "\n",
                "This Q-value update equation is fundamental to the Q-learning algorithm, allowing the agent to iteratively adjust its Q-values based on the rewards received and the expected maximum future reward from the next state. As the agent explores and interacts with the environment, the Q-values converge to optimal values, guiding the agent towards making better decisions and maximizing cumulative rewards. The learning rate `(α)` and discount factor `(γ)` are hyper-parameters that can be tuned to control the learning process in different environments."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Introduction to Dictionaries in Python\n",
                "\n",
                "In Python, a dictionary is a powerful and flexible data structure that allows you to store key-value pairs. It is denoted by curly braces `{}` and consists of keys separated from their corresponding values by a colon `:`. Each key-value pair represents an item in the dictionary. Dictionaries are particularly useful when dealing with data that requires fast and efficient lookup based on unique keys.\n",
                "\n",
                "## Q-Table for the Rock-Paper-Scissors Game\n",
                "\n",
                "In Python dictionaries, including the Q-table, there is no inherent order to the keys. Dictionaries are implemented as hash tables, which are data structures optimised for fast lookup based on keys rather than maintaining a specific order.\n",
                "\n",
                "In the context of the Rock-Paper-Scissors game, we use a dictionary to represent the Q-table. The Q-table maps each `(state, action)` combination to its corresponding Q-value. Here's how we can create the Q-table using a dictionary:\n",
                "\n",
                "```python\n",
                "q_table = {\n",
                "    (\"Rock\", \"Rock\"): 0.0,\n",
                "    (\"Rock\", \"Paper\"): -1.0,\n",
                "    (\"Rock\", \"Scissors\"): 1.0,\n",
                "    (\"Paper\", \"Rock\"): 1.0,\n",
                "    (\"Paper\", \"Paper\"): 0.0,\n",
                "    (\"Paper\", \"Scissors\"): -1.0,\n",
                "    (\"Scissors\", \"Rock\"): -1.0,\n",
                "    (\"Scissors\", \"Paper\"): 1.0,\n",
                "    (\"Scissors\", \"Scissors\"): 0.0\n",
                "}\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.12 ('base')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "9df1b77b0caf646f19509570eac5ef5a3592ebd6cb99175979cb74b7b24a8bf8"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
