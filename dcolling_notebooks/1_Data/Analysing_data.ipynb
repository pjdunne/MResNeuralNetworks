{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time series analysis** refers to the method of breaking down the original dataset into four parts - trends, cycles, periods, and unstable factors - which we adopt to propose forecasts to predict future trends.\n",
    "\n",
    "Time series analysis is one of the **quantitative prediction methods**. It includes general statistical analysis, data filtering, and predicting statistical models. Classical statistical analysis assumes that data sequences are independent of each other, while time series analysis focuses on studying the interdependence of data sequences. The latter is actually a statistical analysis of stochastic processes with discrete indicators, so it can also be seen as a component of stochastic process statistics. For example, by recording the rainfall of the first month, second month,..., and nth month in a certain region, time series analysis methods can be used to predict the future rainfall for each month.\n",
    "\n",
    "In this section of the course, we will see how time series analysis can be applied to moniter the sun's magnetic field. You do not need to understand what the data repersents in-depth, we focus on understandings on how we present, analyse and smooth data in the industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Index: <a id='index'></a>\n",
    "\n",
    "1. [Introducing the Modules](#interest)\n",
    "1. [Importing Data](#importing_data)\n",
    "1. [Plotting Magnetic Field Data](#plotting_data)\n",
    "1. [Calculate the Parker Spiral angle](#parker_angle)\n",
    "1. [Interpolation and NaNs](#interpolation)\n",
    "1. [Multivariate Analysis](#multivariate_analysis)\n",
    "1. [Smoothing Data](#smoothing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will try to use some real experimental time series data to demonstrate how experimental data are being used. We will include the following contents: data interpolation, data smoothing, data filtering, data fitting, and power spectrum.\n",
    "\n",
    "NASA's ```SPICE``` (Space Physics Interactive Data Resource) provides a large amount of data on the sun's magnetic field. The data we use in this session is the sun's magnetic field data from 1996 to 2016. The data is statistically analysed by the Wilcox Solar Observatory (WSO) and is available on the ```SPICE``` website. The data is in the form of a text file, and the data format is as follows:\n",
    "\n",
    "You do not need to understand what the data represents in-depth, we focus on understandings on how we present, analyse and smooth data in the industry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFF8C6\">\n",
    "\n",
    "## For your interest: <a id='interest'></a> [^](#index)\n",
    "\n",
    "- ```sunpy.net.Fido```: This module provides an interface for downloading data from various solar physics data sources using the Fido search and retrieval tool. \n",
    "\n",
    "- ```sunpy.net.attrs``` as a: The attrs submodule of the sunpy.net package provides classes for creating attribute objects that are used to define search criteria for data queries.\n",
    "\n",
    "- ```sunpy.io.cdf```: This module allows reading and writing data in the Common Data Format (CDF). CDF is a self-describing data format used to store and exchange various types of scientific data.\n",
    "\n",
    "- ```sunpy.timeseries.GenericTimeSeries```: This module provides a class for creating a generic time series object in ```SunPy```. Time series data represents measurements or observations taken at multiple time points.\n",
    "\n",
    "- ```sunpy_soar```: This module is a sunpy plugin for accessing data in the Solar Orbiter Archive (SOAR)\n",
    "\n",
    "- ```cdflib```: This module provides tools for reading and writing Common Data Format (CDF) files. CDF is often used for storing and exchanging multidimensional data in various scientific domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "from sunpy.net import Fido, attrs as a \n",
    "import sunpy.io.cdf as cdf\n",
    "from sunpy.timeseries import GenericTimeSeries\n",
    "import sunpy_soar\n",
    "import numpy as np\n",
    "import cdflib\n",
    "import pandas as pd\n",
    "\n",
    "# This is py file located in the same directory as this notebook, refer to the OOP \n",
    "# section of the bootcamp for more information on importing modules\n",
    "import analysis_helpers as h "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data <a id='importing_data'></a> [^](#index)\n",
    "\n",
    "The data we use in this session is the sun's magnetic field data from 1996 to 2016, recorded by instruments on the SOHO satellite.  \n",
    "\n",
    "<div style=\"background-color: #FFF8C6\">\n",
    "\n",
    "Some [background information](https://www.nasa.gov/content/solar-orbiter-instruments) on the data we are using:\n",
    "The Sun's magnetic field extends outwards from our star, filling interplanetary space. Solar Orbiter's ultra-sensitive magnetic field instruments measure the strength and direction of the magnetic field around the spacecraft. This is a complicated, ever-changing characteristic that affects how charged particles move while simultaneously being influenced by the particles themselves as they zip through space. The magnetometer measurements will help scientists address one of Solar Orbiter's primary science questions about the origins of the magnetic field and solar wind plasma in the corona. Magnetic fields also act as a highway for charged particles moving away from the Sun, so magnetometer measurements will also be key to exploring how energetic particle radiation travels out into the solar system following solar eruptions. \n",
    "\n",
    "*The MAG principal investigator is Tim Horbury at the Imperial College London, UK.*\n",
    "\n",
    "</div>\n",
    "\n",
    "You may choose to try to access data documented by other instruments or alternate the time period of the data. You can find the data on the [SPICE website](https://spdf.gsfc.nasa.gov/spice/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011862039566040039,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Files Downloaded",
       "rate": null,
       "total": 0,
       "unit": "file",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb62d729a8eb48ef8e22baaa7622704a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Files Downloaded: 0file [00:00, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create search attributes\n",
    "instrument = a.Instrument('MAG') # Magnetometer\n",
    "time = a.Time('2022-02-08', '2022-03-05') # Time range, you may change this for your own search\n",
    "level = a.Level(2)\n",
    "product = a.soar.Product('MAG-RTN-NORMAL-1-MINUTE') # accessing solar rotaion data on the 1 minute cadence\n",
    "\n",
    "# Search for files\n",
    "result = Fido.search(time & level & product)\n",
    "\n",
    "# Download files\n",
    "files = Fido.fetch(result)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    temp_df = h.cdf2df(file) # Convert the CDF file to a pandas DataFrame for data manipulation\n",
    "    data = pd.concat([data, temp_df])\n",
    "    data.sort_index(inplace=True)# Sort the combined DataFrame by its index in chronological order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(data) # Print the DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Magnetic Field Data <a id='plotting_data'></a> [^](#index)\n",
    "\n",
    "Try to plot the data that we have accessed, refer to the previous session if you need help, and plot the magnetic field data against the time period of the data.\n",
    "\n",
    "**B** refers to the magnetic field strength, and the unit is Gauss. \n",
    "\n",
    "```data['|B|']```: This component represents the magnitude (or absolute value) of the magnetic field vector, ```data['BR']``` is the radial component of the magnetic field, ```data['BT']``` the tangential/transverse component, and ```data['BN']``` is the normal component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the data here\n",
    "\n",
    "#####################\n",
    "\n",
    "# try using subplots for easier comparison between the different components \n",
    "# of the magnetic field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code for subplots\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(4,1,sharex=True)\n",
    "\n",
    "axs[0].plot(data['|B|'], color = 'black')\n",
    "axs[0].set_ylabel('|B|')\n",
    "axs[1].plot(data['BR'], color = 'red')\n",
    "axs[1].set_ylabel('BR')\n",
    "axs[2].plot(data['BT'], color = 'green')\n",
    "axs[2].set_ylabel('BT')\n",
    "axs[3].plot(data['BN'], color = 'orange')\n",
    "axs[3].set_ylabel('BN')\n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Defining polarity - To be Discussed During Lecture <a id='polarity'></a> [^](#index)\n",
    "\n",
    "\n",
    "The solar wind leaves the Sun radially, and travels out into the heliosphere. However, the Sun is spinning at a rate of $14^{\\circ}$/day meaning that the solar wind creates a spiral pattern, the Parker spiral.\n",
    "\n",
    "<center>\n",
    "<img src=\"img/parker_spiral.gif\" />\n",
    "</center>\n",
    "\n",
    "From the \"Frozen-in theorem\", the magnetic field will follow the plasma in the solar wind, therefore, the interplanetary magnetic field does not point radially away from the Sun. So how do we define the magnetic polarity?\n",
    "\n",
    "The Parker spiral angle is given by: $$\\theta = \\arctan(\\frac{- r \\Omega}{V_{sw}})$$\n",
    "\n",
    ",which depends on the spacecraft distance, $r$, and solar wind speed, $V_{sw}$.\n",
    "\n",
    "So we can define the polarity as within $\\pm 45^{\\circ}$ of the nominal Parker spiral direction, as demonstrated here:\n",
    "\n",
    "<center>\n",
    "<img src=\"img/polarity_diagram.png\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding trajectory data\n",
    "Before we can work out the Parker spiral angle by analysing existing, we need the distance of the spacecraft from the Sun.\n",
    "\n",
    "We need to load the right ```SPICE``` kernels, which is not an easy task. I will use a package called ```astrospice```, so it can be done automatically in the notebook.\n",
    "\n",
    "You do not need to know how to access ```SPICE``` but try to understand the type of data we are importing, so we can apply it to calculate the Parker spiral angle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Parker spiral angle <a id='parker_angle'></a> [^](#index)\n",
    "\n",
    "The code snippet below generates the Solar Orbiter's coordinates for specific times using ```astrospice.generate_coords``` and then converts these into Carrington heliographic coordinates, which are solar-centric. This helps pinpoint the spacecraft's position relative to the Sun. The longitude angles are converted to degrees, prepping them for future calculations that require avoiding \"angle wrapping\" from 360 to 0 degrees, which can cause problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astrospice\n",
    "from sunpy.coordinates import HeliographicCarrington\n",
    "import astropy.units as u\n",
    "\n",
    "\n",
    "#get the SPICE kernels\n",
    "solo_kernels = astrospice.registry.get_kernels('solar orbiter', 'predict')\n",
    "solo_kernel = solo_kernels[0]\n",
    "solo_coverage = solo_kernel.coverage('SOLAR ORBITER')\n",
    "print(\"SPICE kernels cover this time period: \", solo_coverage.iso)\n",
    "\n",
    "# use every 30 mins for trajectory, then interpolate\n",
    "times = data.index[::30]\n",
    "\n",
    "#get the coordinates\n",
    "coords = astrospice.generate_coords('SOLAR ORBITER', times)\n",
    "carr_frame = HeliographicCarrington(observer=\"self\")\n",
    "carr_coords = coords.transform_to(carr_frame)\n",
    "\n",
    "# have to make sure there is no wrapping in angles before I interpolate\n",
    "lons = carr_coords.lon.to(u.degree).value\n",
    "# find the break point\n",
    "\n",
    "# keeps unwrapping until a longitude is a straight line, not wrapped around 360\n",
    "while np.any(np.diff(lons) > 10):\n",
    "    lons = h.unwrap_lons(lons)\n",
    "\n",
    "# make a orbit dataframe that I can then interpolate and incorporate into data\n",
    "orbit_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Radius\": carr_coords.radius.to(u.au).value,\n",
    "        \"Carr_lon\": lons,\n",
    "        \"Carr_lat\": carr_coords.lat.to(u.degree).value,\n",
    "    },\n",
    "    index=times,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are NaNs? <a id='interpolation'></a> [^](#index)\n",
    "\n",
    "NaN stands for \"Not a Number\" and is a standard way to denote undefined or unrepresentable values in datasets. These often serve as placeholders for missing or incomplete data.\n",
    "\n",
    "Missing data, represented as NaNs, can introduce bias, lead to loss of statistical power, and significantly affect the conclusions of an analysis. For example, NaNs can skew calculations of mean, median, or correlations, or may lead to gaps in plotted time series data that create misleading visual interpretations.\n",
    "\n",
    "In this section, we have filled in the NaNs with df.interpolate().\n",
    "\n",
    "## Introducing Pandas DataFrame Interpolation\n",
    "\n",
    "The Pandas library offers the `DataFrame.interpolate` method to fill in missing values in a DataFrame. This method uses various interpolation techniques to fill in NaN values with new values. \n",
    "\n",
    "The `DataFrame.interpolate` function in Pandas uses methods like linear interpolation to \"fill in the blanks\" between existing data points. For example, in a time series with missing data at time `t`, Pandas can estimate the missing value based on the values at times `t-1` and `t+1`.\n",
    "\n",
    "In the context of the Solar Orbiter or similar scientific data, interpolation might be used to estimate the spacecraft's position at times when actual readings are not available. The physics behind the interpolation would depend on the understood motion and forces acting upon the object. \n",
    "\n",
    "## Interpolation in Time Series\n",
    "\n",
    "Interpolation is particularly useful in time series analysis where time-ordered data points may be missing. By filling in these points, you can achieve a continuous dataset, making it easier to perform calculations like trend analysis or Fourier transformations. Interpolation in time series commonly uses methods like linear, polynomial, or spline to predict the missing values.\n",
    "\n",
    "\n",
    "## Financial and Stock Market Uses of Interpolation\n",
    "\n",
    "In the finance sector, especially in stock market analysis, interpolation is used to estimate asset prices, rates, or trends for points in time where no data is available. This enables analysts to have a more complete picture of market behaviors. It's especially useful in pricing options or understanding market volatility when historical data may be sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns if they already exist\n",
    "if \"Radius\" in data.keys():\n",
    "    data.drop(\n",
    "        columns=[\"Radius\", \"Carr_lon\", \"Carr_lat\"], inplace=True\n",
    "    )\n",
    "    \n",
    "#re-index to data\n",
    "orbit_df = orbit_df.reindex(data.index)\n",
    "# add the orbit variables in\n",
    "for key in orbit_df.keys():\n",
    "    data[key] = orbit_df[key]\n",
    "\n",
    "#interpolate to fill in the NaNs\n",
    "# I don't want to interpolate the gaps in magnetic field\n",
    "data[['Radius', 'Carr_lon', 'Carr_lat']] = data[\n",
    "    ['Radius', 'Carr_lon', 'Carr_lat']\n",
    "    ].interpolate(method=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Task: Manipulating pandas dataframes:\n",
    "\n",
    "Experiment with your existing knowledge on pandas. \n",
    "\n",
    "1. Creates a fictional \"Velocity\" column and adds it to orbit_df.\n",
    "1. Checks if a \"Velocity\" column already exists in data and removes it if it does.\n",
    "1. Re-indexes orbit_df to match data's index.\n",
    "1. Adds the new \"Velocity\" column to data.\n",
    "1. Performs time-based interpolation on this \"Velocity\" column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code \n",
    "velocity_data = np.random.rand(len(times))\n",
    "\n",
    "orbit_df['Velocity'] = velocity_data\n",
    "\n",
    "\n",
    "if \"Velocity\" in data.keys():\n",
    "    data.drop(columns=[\"Velocity\"], inplace=True)\n",
    "\n",
    "\n",
    "orbit_df = orbit_df.reindex(data.index)\n",
    "\n",
    "data['Velocity'] = orbit_df['Velocity']\n",
    "data['Velocity'] = data['Velocity'].interpolate(method=\"time\")\n",
    "\n",
    "print(orbit_df)\n",
    "\n",
    "# rerun the previous code for the following tasks\n",
    "# if you want to go back to clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is time series and data\n",
    "\n",
    "thruster data, turn into nans, understand quality and interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuing with the parker spiral angle calculation:\n",
    "\n",
    "Here we add a tolerance, tolerances are important as we are dealing with real data, and we need to account for errors in the data, we shall apply the tolerance to the Parker spiral angle calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guess a speed for now, in reality you would get a speed from PAS\n",
    "data['V'] = 350\n",
    "\n",
    "tolerance = 45\n",
    "data = h.add_polarity2df(data, ds_period = '12H',tolerance=tolerance)\n",
    "\n",
    "#angle of magnetic field in R-T plane\n",
    "mag_angle = np.arctan2(data['BT'],data['BR']) *180/np.pi\n",
    "# make the angles go from 0 -> 360\n",
    "mag_angle[mag_angle<0] += 360\n",
    "data['mag_angle'] = mag_angle\n",
    "\n",
    "data['PS_angle'] = h.PS_angle(data['Radius'].values*u.au, data['V'].values*u.km/u.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariante Analysis <a id='multivariate_analysis'></a> [^](#index)\n",
    "\n",
    "\n",
    "Here we plot `data['|B|']`, `data['BR']` and `data['BT']` `data['BN']` against the time period. Adding appropriate labels and titles to the plot.\n",
    "\n",
    "<div style=\"background-color:#C2F5DD\">\n",
    "Task: Plot the Parker spiral angle and the polarity against the time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, sharex = True, figsize = (10,10))\n",
    "axs[0].plot(data['|B|'], color = 'black', label = '|B|')\n",
    "axs[0].plot(data['BR'], color = 'red', label = 'BR')\n",
    "axs[0].legend(loc = 'upper left')\n",
    "\n",
    "axs[1].plot(data['BT'], color = 'orange', label = 'BT')\n",
    "axs[1].plot(data['BN'], color = 'green', label = 'BN')\n",
    "axs[1].legend(loc = 'upper left')\n",
    "\n",
    "axs[0].set_ylabel('|B|, BR (nT)')\n",
    "axs[1].set_ylabel('BT, BN (nT)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, sharex = True, figsize = (10,10))\n",
    "\n",
    "for ax in axs[:0]:\n",
    "    ax.axhline(0, color = 'black', lw = 1, ls = 'dotted')\n",
    "\n",
    "axs[0].scatter(data.index, data['mag_angle'], color = 'black', s = 1)\n",
    "axs[0].fill_between(data.index, data['PS_angle'] +tolerance, data['PS_angle'] -tolerance, color = 'red', alpha = 0.2)\n",
    "axs[0].fill_between(data.index, data['PS_angle'] -180 +tolerance, data['PS_angle'] -180 -tolerance, color = 'blue', alpha = 0.2)\n",
    "axs[0].set_ylabel('Mag. angle ($^{\\circ}$)')\n",
    "\n",
    "\n",
    "axs[1].plot(data['polarity'], color = 'green')\n",
    "axs[1].set_ylabel('Polarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Smoothing <a id='smoothing_data'></a> [^](#index)\n",
    "\n",
    "Data smoothing is a technique that involves removing noise from a dataset to make a dataset easier to analyse. Smoothing can be performed in a variety of ways, including averaging, binning, and splining. \n",
    "\n",
    "<div style=\"background-color:#C2F5DD\">\n",
    "Task: Search up the different types of smoothing and try to apply them to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try to smooth the magnetic field data and plot it against time\n",
    "\n",
    "#####################\n",
    "\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "# Apply a moving average with a window size of 10\n",
    "data['Smoothed_B_MovingAvg'] = data['|B|'].rolling(window=10).mean()\n",
    "\n",
    "# Apply Gaussian smoothing with a sigma of 10\n",
    "data['Smoothed_B_Gaussian'] = gaussian_filter(data['|B|'], sigma=10)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, sharex=True, figsize=(10, 10))\n",
    "\n",
    "axs[0].plot(data.index, data['|B|'], label='Original |B|', color='yellow')\n",
    "axs[0].plot(data.index, data['Smoothed_B_MovingAvg'], label='Moving Average Smoothed |B|', color='red')\n",
    "\n",
    "axs[1].plot(data.index, data['|B|'], label='Original |B|', color='yellow')\n",
    "axs[1].plot(data.index, data['Smoothed_B_Gaussian'], label='Gaussian Smoothed |B|', color='blue')\n",
    "\n",
    "axs[0].set_ylabel('|B| (nT)')\n",
    "axs[0].set_title('Magnetic Field Intensity with Smoothing')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_xlabel('Time')\n",
    "axs[1].set_ylabel('|B| (nT)')\n",
    "axs[1].legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data <a id='filtering_data'></a> [^](#index)\n",
    "\n",
    "Here we have used two times of filters, a moving average filter and a gaussian filter.\n",
    "\n",
    "A moving average filter is a simple, finite impulse response (FIR) filter commonly used in signal processing and time-series analysis. It works by averaging a set of data points within a moving window over the data. The window slides along the data, and at each position, the average of the data points within the window is calculated. This is a simple way to smooth out data and reduce noise within a dataset.\n",
    "\n",
    "Using a Gaussian filter on time-series magnetic field data from the Sun offers multiple advantages, including effective noise reduction while preserving important features like sudden changes in magnetic field strength, which could indicate solar events. The filter's weighted averaging is particularly useful for highlighting localised events. It also performs well in both time and frequency domains, allowing for a nuanced analysis of the Sun's complex magnetic field dynamics. The filter is adaptable, with adjustable standard deviation for tailored sensitivity, and can be computationally efficient with optimised algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High and Low Pass Filters Using fft\n",
    "\n",
    "How do we apply the usage of filters here? split the data into useful sections?\n",
    "\n",
    "Scipy has a [built-in](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html) function for this, `scipy.signal.butter`, which can be used to apply a high/low pass filter to the data.\n",
    "\n",
    "- [`scipy.signal.butter`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html)\n",
    "- [`scipy.signal.filtfilt`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.filtfilt.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_freq, sample_rate):\n",
    "    b, a = butter(N=6, Wn=cutoff_freq / (0.5 * sample_rate), btype='low')\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def butter_highpass_filter(data, cutoff_freq, sample_rate):\n",
    "    b, a = butter(N=6, Wn=cutoff_freq / (0.5 * sample_rate), btype='high')\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Spectrum\n",
    "\n",
    "used to analyse periodic signals or signals that have a periodic component and determine the strength of each frequency component.\n",
    "\n",
    "In the analysis of the suns magnetic field, we can use the power spectrum to analyse periodic patterns???\n",
    "\n",
    "Smoothing techniques like moving average or Gaussian filters can be applied before Fourier Transform and power spectrum analysis to reduce noise. Smoothing can make it easier to identify true frequency components by eliminating or reducing spurious peaks in the power spectrum that are due to noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('testX')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d56cc16d861913ffbcda9b6300d2a9b1f4537e9ddc8b105371ad79de78aa931"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
